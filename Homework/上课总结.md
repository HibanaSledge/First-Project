8月8日：

上课时间：两小时

上课形式：网课

上课内容：Python的基础编程。安装了anaconda，pycharm等学习python所需要的软件以及相应的软件包。了解算法的流程。

一般算法的流程具体分为如下几个步骤：首先将数据分为三类：测试集，训练集以及验证集。测试集的数据主要用于对算法模型的预测。训练集的数据主要用于模型的构造以及进行迭代训练。在迭代训练完成以后，再使用验证集里面的数据对模型进行验证，并根据验证结果对整个模型做出分析和结论。

第二部分是软件的应用，包括Anaconda以及Pycharm。Anaconda是一个集成性软件，里面包含了很多编程以及算法中可能需要用到的包或者软件，比如keras。Pycharm则是一个专门用于编写Python的编译器，虽然我们也可以用Jupyter notebook进行在线编译，但Pycharm一是脱离了对网络的需求，二是在编写时有很多提示，对于初学者很有帮助。









8.15：



上课时间：2小时

上课形式：面对面授课

上课内容：Mobaxterm，git以及keras的安装和使用，BP（Back Propagation)神经网络介绍



首先在Windows系统中安装了Mobaxterm，一款可以远程控制其他电脑的软件，在以后的学习中会有所帮助。Git则是一个传输和保存代码的软件，可以通过git将写好的代码打包上传至Github在云端储存，也可以通过git将别人发送过来的Github链接保存并读取里面的文件。Keras则是一个主流的深度学习框架，但只是进行了下载和大致的了解，并没有深入的研究和学习。



BP（Back Propagation）神经网络是一个非常基础的深度学习的网络，分为输入层，隐藏层和输出层。通过函数的计算，将结果输出到下一层，再用下一层的结果代入函数中进行运算，并不断重复此过程知到得到想要的计算结果，即为输出层。中间的计算部分均为隐藏层。一般而言，通常最终的结果在0-1之间是最合适的，避免某个输入过大，影响了最终的输出层。



为了使结果尽可能准确，同时还需要减少其中的loss部分。也可以理解为整个网络的训练其实就是一个不断减少loss的过程。这个过程可以通过求导来完成，即找到在某一个点的时候，loss的值为最小。在二维空间中，这样的一个点可能是函数线段的某一个切点，而在三维空间中，这样的点通常位于最底部，也就是”碗底“。通过不断的求导，最终找出这个点的坐标，这种方法也被称为梯度下降求解法。







